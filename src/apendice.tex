\section{Apéndice}
\label{sec:apendice}

\subsection{Datos obtenidos del experimento}

\begin{table}[H]
    \footnotesize
    \centering
    \begin{tabular}{r|rrrr}\toprule
        \input{src/apendice/datos}
    \end{tabular}
\end{table}

\subsection{Justificación del uso de $T$ vs. $\sqrt{L}$}
\label{sec:apendice:justificacion}

Se parte de la ecuación \ref{ec:intro:gravedad} y se despeja

\[
    g = \frac{8}{3}\pi^2 \frac{x}{y^2}
\]
donde se pueden dar las siguientes situaciones:

\begin{multicols}{3}
\begin{itemize}
    \item $x = L$ e $y = T$
    \item $x = \sqrt{L}$ e $y = T$
    \item $x = L$ e $y = T^2$
\end{itemize}
\end{multicols}

Al propagar el error de $g$ se obtiene:

\[
    \Delta g = \frac{8}{3}\pi^2 \left(
        \frac{\Delta x}{y^2} + 
        \frac{2x\Delta y}{y^3}
    \right)
\]

Por lo tanto $\Delta g$ depende directamente de los errores de $L$ y $T$.
Propagando los errores de $\sqrt{L}$ y $T^2$ se obtiene

\[
    \Delta \left(\sqrt{L}\right) = \frac{\Delta L}{2\sqrt{L}},
    \quad\quad
    \Delta \left( T^2 \right) = 2T\Delta T
\]

Lo que implica que el error de $\sqrt{L}$ es menor que $\Delta L$, y que 
el error de $T^2$ es mayor que $\Delta T$. Por lo tanto la mejor forma de 
disminuir el error en $g$ al utilizar mínimos cuadrados es usar un gráfico
$T$ vs. $\sqrt{L}$. 

\subsection{Fórmulas para el cálculo de estimadores en mínimos cuadrados}
\label{sec:apendice:formulas-estimadores-mc}

Sea $y_i = Bx_i + A$ una recta que ajusta una serie de $N$ datos mediante
cuadrados mínimos. La pendiente $B$ y la ordenada al origen $A$ se calculan
como:

\newcommand{\denominador}{N \sum {x_i}^2 - \left( \sum x_i \right)^2} 

\begin{equation}
    \label{ec:apendice:pendiente-mc}
    B = \frac{ N \sum x_i y_i - \sum x_i \sum y_i }
             { \denominador }
\end{equation}
\vspace{5mm}
\begin{equation}
    \label{ec:apendice:ordenada-mc}
    A = \frac{ \sum {x_i}^2 \sum y_i - \sum x_i \sum x_i y_i}
             { \denominador }
\end{equation}
\vspace{5mm}

A su vez, se puede calcular la desviación de $y_i$ como:

\begin{equation}
    \label{ec:apendice:desviacion-y-mc}
    \sigma_{y_i} = \sqrt{ \frac{1}{N-2} \sum 
                          \left( y_i - A - B x_i \right)^2 }
\end{equation}

\vspace{5mm}
La desviación de la pendiente y de la ordenada pueden calcularse como:

\begin{equation}
    \label{ec:apendice:desviacion-pendiente-mc}
    \sigma_B = \sigma_{y_i} \sqrt { \frac{N}{\denominador} }
\end{equation}

\vspace{5mm}
\begin{equation}
    \label{ec:apendice:desviacion-ordenada-mc}
    \sigma_A = \sigma_{y_i} \sqrt { \frac{ \sum {x_i}^2 }{ \denominador } }
\end{equation}

\vspace{5mm}
Finalmente se puede calcular el error en la pendiente y en la ordenada como:

\begin{equation}
    \label{ec:apendice:errores-mc}
    \Delta B = \frac{3\,\sigma_B}{\sqrt{N}}, \quad\quad
    \Delta A = \frac{3\,\sigma_A}{\sqrt{N}}
\end{equation}
